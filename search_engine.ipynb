{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\miniconda3\\envs\\CS336\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = CLIPModel.from_pretrained('openai/clip-vit-base-patch32')\n",
    "processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch32')\n",
    "\n",
    "transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    # Kiểm tra nếu data là một vector 1 chiều\n",
    "    if data.ndim == 1:\n",
    "        normalized_data = data / np.linalg.norm(data)\n",
    "    else:\n",
    "        # Chuẩn hóa dữ liệu nếu là mảng 2 chiều\n",
    "        normalized_data = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "    \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clip_feature(images, device='cpu'):\n",
    "#   images = [Image.open(path).convert('RGB') for path in image_paths]\n",
    "  features = []\n",
    "  for image in images:\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feature = model.get_image_features(image)\n",
    "    feature = feature.squeeze().cpu().numpy()\n",
    "    features.append(feature)\n",
    "\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = r'C:\\Retrieval System\\data\\paris_120310_gt'\n",
    "data_path = r'C:\\Retrieval System\\data\\paris'\n",
    "features_path = r'C:\\Retrieval System\\features\\features_paris_clip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_queries(query_file, device='cpu'):\n",
    "    \"\"\"\n",
    "    Đọc file query, cắt ảnh theo bounding box và extract feature theo từng bb.\n",
    "    \n",
    "    :param query_file: Đường dẫn đến file query.txt\n",
    "    :param image_folder: Thư mục chứa ảnh\n",
    "    \"\"\"\n",
    "    with open(query_file, 'r') as file:\n",
    "        features = []\n",
    "        for line in file:\n",
    "            # Tách dòng query thành các phần tử\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            \n",
    "            image_name = parts[0] + '.jpg'  # Tên file ảnh\n",
    "            x1, y1, x2, y2 = map(float, parts[1:])  # Bounding box\n",
    "            \n",
    "            # Đường dẫn đầy đủ đến ảnh\n",
    "            image_path = os.path.join(data_path, image_name.split('_')[1], image_name)\n",
    "            \n",
    "            # Kiểm tra ảnh tồn tại\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Ảnh {image_name} không tồn tại trong thư mục {os.path.join(data_path, image_name.split('_')[1])}.\")\n",
    "                continue\n",
    "            \n",
    "            # Mở ảnh và cắt theo bounding box\n",
    "            with Image.open(image_path).convert('RGB') as img:\n",
    "                cropped_img = img.crop((x1, y1, x2, y2))  # Cắt ảnh\n",
    "                # Extract feature của ảnh crop\n",
    "                cropped_img = transform(cropped_img).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    feature = model.get_image_features(cropped_img)\n",
    "                feature = feature.squeeze().cpu().numpy()\n",
    "                features.append(feature)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defense_1_query.txt\n",
      "defense_2_query.txt\n",
      "defense_3_query.txt\n",
      "defense_4_query.txt\n",
      "defense_5_query.txt\n",
      "eiffel_1_query.txt\n",
      "eiffel_2_query.txt\n",
      "eiffel_3_query.txt\n",
      "eiffel_4_query.txt\n",
      "eiffel_5_query.txt\n",
      "invalides_1_query.txt\n",
      "invalides_2_query.txt\n",
      "invalides_3_query.txt\n",
      "invalides_4_query.txt\n",
      "invalides_5_query.txt\n",
      "louvre_1_query.txt\n",
      "louvre_2_query.txt\n",
      "louvre_3_query.txt\n",
      "louvre_4_query.txt\n",
      "louvre_5_query.txt\n",
      "moulinrouge_1_query.txt\n",
      "moulinrouge_2_query.txt\n",
      "moulinrouge_3_query.txt\n",
      "moulinrouge_4_query.txt\n",
      "moulinrouge_5_query.txt\n",
      "museedorsay_1_query.txt\n",
      "museedorsay_2_query.txt\n",
      "museedorsay_3_query.txt\n",
      "museedorsay_4_query.txt\n",
      "museedorsay_5_query.txt\n",
      "notredame_1_query.txt\n",
      "notredame_2_query.txt\n",
      "notredame_3_query.txt\n",
      "notredame_4_query.txt\n",
      "notredame_5_query.txt\n",
      "pantheon_1_query.txt\n",
      "pantheon_2_query.txt\n",
      "pantheon_3_query.txt\n",
      "pantheon_4_query.txt\n",
      "pantheon_5_query.txt\n",
      "pompidou_1_query.txt\n",
      "pompidou_2_query.txt\n",
      "pompidou_3_query.txt\n",
      "pompidou_4_query.txt\n",
      "pompidou_5_query.txt\n",
      "sacrecoeur_1_query.txt\n",
      "sacrecoeur_2_query.txt\n",
      "sacrecoeur_3_query.txt\n",
      "sacrecoeur_4_query.txt\n",
      "sacrecoeur_5_query.txt\n",
      "triomphe_1_query.txt\n",
      "triomphe_2_query.txt\n",
      "triomphe_3_query.txt\n",
      "triomphe_4_query.txt\n",
      "triomphe_5_query.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55, 512)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = []\n",
    "for file in os.listdir(gt_path):\n",
    "    if 'query' in file:\n",
    "        print(file)\n",
    "        query_file = os.path.join(gt_path, file)\n",
    "        features = process_queries(query_file=query_file)\n",
    "        if len(features) == 1:\n",
    "            query.append(features[0])\n",
    "\n",
    "input_features = np.array(query)\n",
    "input_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6392, 512)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = []\n",
    "map_db = []\n",
    "for file in os.listdir(features_path):\n",
    "    file_path = os.path.join(features_path, file)\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        image_features_data = pickle.load(f) # 1 list, các phần tử là dict với image_name và features\n",
    "\n",
    "        for item in image_features_data:\n",
    "            database.append(item['features'])\n",
    "            map_db.append(item['image_name'])\n",
    "\n",
    "database = np.array(database)\n",
    "database.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7190387 , 0.7383275 , 0.7878091 , ..., 0.67330176, 0.6710704 ,\n",
       "       0.6382113 ], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = cosine_similarity(query, database)\n",
    "similarity_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  57  168   78 ... 3410 3743 3903]\n"
     ]
    }
   ],
   "source": [
    "sorted_similarity_indices = np.argsort(similarity_matrix, axis=1)[:, ::-1]\n",
    "print(sorted_similarity_indices[0])\n",
    "\n",
    "# Sắp xếp lại map_db theo thứ tự của similarity_matrix\n",
    "sorted_map_db = []\n",
    "for i in range(similarity_matrix.shape[0]):\n",
    "    sorted_map_db.append([map_db[j] for j in sorted_similarity_indices[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS336",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
