{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = r'C:\\Retrieval System\\features\\features_clip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    # Kiểm tra nếu data là một vector 1 chiều\n",
    "    if data.ndim == 1:\n",
    "        normalized_data = data / np.linalg.norm(data)\n",
    "    else:\n",
    "        # Chuẩn hóa dữ liệu nếu là mảng 2 chiều\n",
    "        normalized_data = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "    \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6392, 512)\n",
      "512\n",
      "True\n",
      "6392\n"
     ]
    }
   ],
   "source": [
    "save_name_file = []\n",
    "features = []\n",
    "\n",
    "for file in os.listdir(features_path):\n",
    "    file_path = os.path.join(features_path, file)\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        image_features_data = pickle.load(f) # 1 list, các phần tử là dict với image_name và features\n",
    "\n",
    "        for item in image_features_data:\n",
    "            features.append(item['features'])\n",
    "            save_name_file.append(item['image_name'])\n",
    "\n",
    "db = np.array(features)\n",
    "print(db.shape)\n",
    "\n",
    "d = db.shape[1]\n",
    "print(d)\n",
    "nb = db.shape[0]\n",
    "# nq = query_beit.shape[0]\n",
    "\n",
    "index = faiss.IndexFlatIP(d)   # build the index\n",
    "print(index.is_trained)\n",
    "index.add(normalize_data(db))  # add vectors to the index\n",
    "print(index.ntotal)\n",
    "\n",
    "# save_path = os.path.join(r'C:\\Retrieval System\\Multimedia-Information-Retrieval\\index', 'feature_paris_clip.pkl')\n",
    "# Lưu index và danh sách vào file\n",
    "# with open(save_path, \"wb\") as f:\n",
    "#     pickle.dump({\"index\": index, \"map_index\": save_name_file}, f)\n",
    "# print('hehe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\miniconda3\\envs\\CS336\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\DELL\\miniconda3\\envs\\CS336\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\miniconda3\\envs\\CS336\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['defense_1', 'defense_2', 'defense_3', 'defense_4', 'defense_5', 'eiffel_1', 'eiffel_2', 'eiffel_3', 'eiffel_4', 'eiffel_5', 'invalides_1', 'invalides_2', 'invalides_3', 'invalides_4', 'invalides_5', 'louvre_1', 'louvre_2', 'louvre_3', 'louvre_4', 'louvre_5', 'moulinrouge_1', 'moulinrouge_2', 'moulinrouge_3', 'moulinrouge_4', 'moulinrouge_5', 'museedorsay_1', 'museedorsay_2', 'museedorsay_3', 'museedorsay_4', 'museedorsay_5', 'notredame_1', 'notredame_2', 'notredame_3', 'notredame_4', 'notredame_5', 'pantheon_1', 'pantheon_2', 'pantheon_3', 'pantheon_4', 'pantheon_5', 'pompidou_1', 'pompidou_2', 'pompidou_3', 'pompidou_4', 'pompidou_5', 'sacrecoeur_1', 'sacrecoeur_2', 'sacrecoeur_3', 'sacrecoeur_4', 'sacrecoeur_5', 'triomphe_1', 'triomphe_2', 'triomphe_3', 'triomphe_4', 'triomphe_5']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55, 512)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "\n",
    "gt_path = r'C:\\Retrieval System\\data\\paris_120310_gt'\n",
    "data_path = r'C:\\Retrieval System\\data\\paris'\n",
    "features_path = r'C:\\Retrieval System\\features\\features_paris_clip_3'\n",
    "\n",
    "model = CLIPModel.from_pretrained('openai/clip-vit-base-patch32')\n",
    "processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch32')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "def process_queries(query_file, device='cpu'):\n",
    "    \"\"\"\n",
    "    Đọc file query, cắt ảnh theo bounding box và extract feature theo từng bb.\n",
    "    \n",
    "    :param query_file: Đường dẫn đến file query.txt\n",
    "    :param image_folder: Thư mục chứa ảnh\n",
    "    \"\"\"\n",
    "    with open(query_file, 'r') as file:\n",
    "        features = []\n",
    "        for line in file:\n",
    "            # Tách dòng query thành các phần tử\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            \n",
    "            image_name = parts[0] + '.jpg'  # Tên file ảnh\n",
    "            x1, y1, x2, y2 = map(float, parts[1:])  # Bounding box\n",
    "            \n",
    "            # Đường dẫn đầy đủ đến ảnh\n",
    "            image_path = os.path.join(data_path, image_name.split('_')[1], image_name)\n",
    "            \n",
    "            # Kiểm tra ảnh tồn tại\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Ảnh {image_name} không tồn tại trong thư mục {os.path.join(data_path, image_name.split('_')[1])}.\")\n",
    "                continue\n",
    "            \n",
    "            # Mở ảnh và cắt theo bounding box\n",
    "            with Image.open(image_path).convert('RGB') as img:\n",
    "                cropped_img = img.crop((x1, y1, x2, y2))  # Cắt ảnh\n",
    "                # Extract feature của ảnh crop\n",
    "                cropped_img = transform(cropped_img).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    feature = model.get_image_features(cropped_img)\n",
    "                feature = feature.squeeze().cpu().numpy()\n",
    "                features.append(feature)\n",
    "        \n",
    "        return features\n",
    "\n",
    "query = []\n",
    "map_qr = []\n",
    "for file in os.listdir(gt_path):\n",
    "    if 'query' in file:\n",
    "        # print(file)\n",
    "        map_qr.append(file.split('.')[0])\n",
    "        query_file = os.path.join(gt_path, file)\n",
    "        features = process_queries(query_file=query_file)\n",
    "        if len(features) == 1:\n",
    "            query.append(features[0])\n",
    "\n",
    "query = np.array(query)\n",
    "map_qr = [name[:-6] if name.endswith(\"_query\") else name for name in map_qr]\n",
    "print(map_qr)\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 329   43  162   42  316]\n",
      " [ 164   43  329  359  298]\n",
      " [  86  125  329  162   43]\n",
      " [ 175  224  164   43  178]\n",
      " [  43  329  162   86  132]\n",
      " [1255 1411 1748 1923  626]\n",
      " [1274  686  392  785  477]\n",
      " [1411 1224  420 1748  838]\n",
      " [1923 1748  626 1255 1228]\n",
      " [ 922  657  460 1360  477]\n",
      " [2182 2294 2035 2455 2289]\n",
      " [2182 2035 2294 2447 2225]\n",
      " [2182 2263 2035 2060 2468]\n",
      " [2294 2434 2188 2225 2147]\n",
      " [2035 2182 2294 2263 2468]\n",
      " [2647 2579 1068 2654 2527]\n",
      " [2582 2655 2708 2606 2511]\n",
      " [2646 2645 2608 2708 2610]\n",
      " [2608 2645 2646 2708 2582]\n",
      " [2582 2567 2708 2579 1068]\n",
      " [2859 3158 2993 3082 3000]\n",
      " [3082 3108 3158  757 3000]\n",
      " [3082 2901 2993 2859  757]\n",
      " [3108 2822 3082 2993 2859]\n",
      " [2822 3108  757 3158 3082]\n",
      " [3311 3876 3571 3731 3240]\n",
      " [3240 3731 3453 3311 3876]\n",
      " [3240 3876 3731 3571 3311]\n",
      " [3876 3311 3571 3731 3240]\n",
      " [3731 3571 3876 3453 3240]\n",
      " [3966 4352 4250 4240 4135]\n",
      " [4123 4251 4228 4135 4076]\n",
      " [4238 4076 4135 4163 4284]\n",
      " [4135  985 4250 4240 4284]\n",
      " [4179 4135 4078 4163 4284]\n",
      " [4813 4427 4769 4684 4697]\n",
      " [4619 4697 5006 4978 4578]\n",
      " [5006 4622 4472 4825 4959]\n",
      " [5020 5006 4622 4935 4923]\n",
      " [5006 4978 4622 4697 4619]\n",
      " [5439 5319 5108 5372 5167]\n",
      " [5113 5108 5313 5161 5190]\n",
      " [5309 5263 5083 5230 5372]\n",
      " [5230 5263 5161 5312 5376]\n",
      " [5372 5123 5319 5167 5317]\n",
      " [5527 5617 5522 5613 5546]\n",
      " [5502 5827 5527 5638 5575]\n",
      " [5786 5617 5522 5527 5619]\n",
      " [5638 5827 5527 5836 5542]\n",
      " [5527 5617 5522 5546 5613]\n",
      " [6024 6270 5938 6001 6171]\n",
      " [6117 6282  769 6166 6293]\n",
      " [5995 6050 6165 6135  293]\n",
      " [6282 6384 6226 1033 6333]\n",
      " [6088 6006  293 6044 6369]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "k = 5\n",
    "distances, indices = index.search(query, k)\n",
    "print(indices)\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"FALSE\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS336",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
